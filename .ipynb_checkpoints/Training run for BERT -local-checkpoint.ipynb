{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a24020-7015-4083-bdbd-1347029fa855",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Evaluating Sequence Classification Models\r\n",
    "\r\n",
    "In this notebook, we'll take the next steps in our project: we'll fine-tune our prepared BERT models on our training set and evaluate their performance. \r\n",
    "\r\n",
    "This process involves running Python scripts that execute the training process and test the resulting models on our test set. The metrics of our models' performance are crucial in understanding how well our fine-tuning process has worked. We will look at these metrics in two ways: \r\n",
    "\r\n",
    "1. **In-notebook review:** We'll print the confusion matrix and classification reports within this notebook for an immediate review of our models' performance.\r\n",
    "\r\n",
    "2. **Saving reports:** To ensure we have a permanent record of our results, we'll also save these performance metrics in a separate 'reports' folder. This allows us to track our progress over time and make comparisons between different models and iterations of fine-tuning.\r\n",
    "\r\n",
    "Remember, the fine-tuning and evaluation process can be iterative. Based on the results we see in our reports, we may want to adjust our approach and fine-tune our models differently. \r\n",
    "\r\n",
    "In this notebook, we'll cover the following steps:\r\n",
    "\r\n",
    "1. Running the training scripts: We'll call our Python scripts that handle the fine-tuning of our models on the training set.\r\n",
    "2. Running the testing scripts: We'll test the performance of our newly fine-tuned models on our test set.\r\n",
    "3. Reviewing the results: We'll print and save our confusion matrices and classification reports.\r\n",
    "\r\n",
    "Let's get started!\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5c4a21-c270-43f4-8cc1-ec50fec917c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainBERTovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dae72-065b-40df-972f-b4c8267c9146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTovoSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTovoSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 27:06, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017485</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020884</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b757fb76faeb405a9c5b98aa287f61a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   72d4386..3c5e95a  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   3c5e95a..c5e696d  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.35 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.35 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4755b897-48d8-443c-b25b-c0b11e939862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3946  974]\n",
      " [  31    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      4920\n",
      "           1       0.01      0.16      0.01        37\n",
      "\n",
      "    accuracy                           0.80      4957\n",
      "   macro avg       0.50      0.48      0.45      4957\n",
      "weighted avg       0.98      0.80      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51f778f6-3e9b-4e86-88f5-df36f79c90b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainBERTic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73125c37-14f2-48eb-95e2-fc3fd9ec940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTicSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTicSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 25:02, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.996638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045761</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027412</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.996638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985618539bad401ba29043d18d02d273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   b96e2f0..ec157f4  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   ec157f4..20f6944  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.35 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.35 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0705446-4984-4b9d-9de6-b125cc2912fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40793bd6385b4ba3a8314d7e5832753f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daddb36c476e440f9b2956dd633aa3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facf65a6ed2649a7902a5af0fe6ffec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d592f7da76df4681a58190556fb3b1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257dc6339d4242268b95b7259987eb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1167c04e117429ebe6a944e44d516c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4909   11]\n",
      " [  13   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4920\n",
      "           1       0.69      0.65      0.67        37\n",
      "\n",
      "    accuracy                           1.00      4957\n",
      "   macro avg       0.84      0.82      0.83      4957\n",
      "weighted avg       1.00      1.00      1.00      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea65ca59-1270-4158-a843-42421fa47e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f934bdfda014a5ea25bebc17655f6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d387459ba8fa425f9ac5faa6d3076d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60765e7fbb947d38ec67eb29a288e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/520k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14589224600418ab916e279265a9802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30087d8c61334aecbf0aee746b210762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b994fafcbaf840ee8b6ac0c023365de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588ab72e768544e187ef43848df29669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/574M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTovoSENTNEG0 into local empty directory.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 27:25, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.988568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.988568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061454</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.063018</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.064784</td>\n",
       "      <td>0.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.068851</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.072809</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075512</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075477</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cdfea44434423299c9deed7db4b7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTNEG0\n",
      "   03b942e..f913314  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTNEG0\n",
      "   f913314..f93ff01  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.57 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.57 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a752fa1-1bf0-4ad6-9d83-a016eede1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b9f9e-b564-4d9b-b7fb-0c154ee4ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.train_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6098e-82b3-471b-8cb2-cfd6ac416ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382eb9a-2eb5-4b73-a693-9d13166009d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
