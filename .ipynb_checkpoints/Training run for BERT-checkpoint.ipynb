{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a24020-7015-4083-bdbd-1347029fa855",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Performance Evaluation of BERT Models for Sentiment Classification\r\n",
    "\r\n",
    "In this Jupyter notebook, we delve into the crucial steps of our Natural Language Processing (NLP) project - fine-tuning our preprocessed BERT models on the Serbian Wordnet training data, and assessing their performance. \r\n",
    "\r\n",
    "Our primary objective is to adapt BERT models to effectively classify sentiments, leveraging a semi-automated, iterative approach that uses seed words and expands them based on their relationships in WordNet. \r\n",
    "\r\n",
    "The performance evaluation metrics are instrumental in assessing the success of our fine-tuning process. We will analyze these metrics in two ways:\r\n",
    "\r\n",
    "1. **In-notebook Review:** For an immediate performance evaluation, we will print the confusion matrix and classification reports within this notebook.\r\n",
    "\r\n",
    "2. **Persistent Reports:** We'll create a lasting record of our results by storing these metrics in a separate 'reports' folder. This approach facilitates progress tracking over time, and enables comparisons among different models and fine-tuning iterations.\r\n",
    "\r\n",
    "Keep in mind that the fine-tuning and evaluation processes are iterative. Based on our results and insights, we may need to adjust our strategies and fine-tune our models differently.\r\n",
    "\r\n",
    "Throughout this notebook, we will go through:\r\n",
    "\r\n",
    "1. **Model Training:** Execution of Python scripts for fine-tuning our BERT models on the training set.\r\n",
    "2. **Model Testing:** Performance evaluation of the newly fine-tuned models on our test data.\r\n",
    "3. **Results Analysis:** Examination, interpretation, and storage of the confusion matrices and classification reports.\r\n",
    "\r\n",
    "Let's embark on th exciting journey!\r\n",
    "Let's get started!\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7e9a2-0291-484e-bb30-1e04d1799faa",
   "metadata": {},
   "source": [
    "### Importing Required Modules\r\n",
    "\r\n",
    "In this initial code cell, we import the necessary modules that contain functions for training and testing our BERT models. The modules imported are:\r\n",
    "\r\n",
    "1. **`trainBERTovo`:** This module contains the `train_model` and `test_model` functions for handling the training and testing processes respectively. The BERT model used in this module is the \"Jerteh\" model, which is pre-trained exclusively on the Serbian language using a RoBERTa architecture. It is tailored to deal with the specificities of the Serbian language, managing everything from data preprocessing to model training, testing, and memory management for GPU use.\r\n",
    "\r\n",
    "2. **`trainBERTic`:** Similar to `trainBERTovo`, this module also contains `train_model` and `test_model` functions. However, the BERT model used in this module is the \"Classla\" model, which is based on the ELECTRA model and is multilingual, including support for Serbian among other regional languages.\r\n",
    "\r\n",
    "By encapsulating the training and testing processes within these modules, we maintain a clean and streamlined notebook. This allows us to focus on the implementation, results interpretation, and performance evaluation of the models.\r\n",
    "erstand.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3670d233-eeca-4faf-90a9-a2a65d777043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainBERTovo\n",
    "import trainBERTic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dae72-065b-40df-972f-b4c8267c9146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTovoSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTovoSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 27:06, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017485</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020884</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b757fb76faeb405a9c5b98aa287f61a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   72d4386..3c5e95a  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   3c5e95a..c5e696d  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.35 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.35 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4755b897-48d8-443c-b25b-c0b11e939862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3946  974]\n",
      " [  31    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      4920\n",
      "           1       0.01      0.16      0.01        37\n",
      "\n",
      "    accuracy                           0.80      4957\n",
      "   macro avg       0.50      0.48      0.45      4957\n",
      "weighted avg       0.98      0.80      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73125c37-14f2-48eb-95e2-fc3fd9ec940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTicSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTicSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 25:02, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018174</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.996638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031349</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045761</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027412</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026832</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.996638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.029421</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985618539bad401ba29043d18d02d273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   b96e2f0..ec157f4  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   ec157f4..20f6944  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.35 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.35 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0705446-4984-4b9d-9de6-b125cc2912fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40793bd6385b4ba3a8314d7e5832753f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daddb36c476e440f9b2956dd633aa3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facf65a6ed2649a7902a5af0fe6ffec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d592f7da76df4681a58190556fb3b1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257dc6339d4242268b95b7259987eb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1167c04e117429ebe6a944e44d516c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4909   11]\n",
      " [  13   24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4920\n",
      "           1       0.69      0.65      0.67        37\n",
      "\n",
      "    accuracy                           1.00      4957\n",
      "   macro avg       0.84      0.82      0.83      4957\n",
      "weighted avg       1.00      1.00      1.00      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea65ca59-1270-4158-a843-42421fa47e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f934bdfda014a5ea25bebc17655f6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d387459ba8fa425f9ac5faa6d3076d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60765e7fbb947d38ec67eb29a288e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/520k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14589224600418ab916e279265a9802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30087d8c61334aecbf0aee746b210762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b994fafcbaf840ee8b6ac0c023365de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/833 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588ab72e768544e187ef43848df29669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/574M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTovoSENTNEG0 into local empty directory.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 27:25, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.988568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.988568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061454</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.063018</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.064784</td>\n",
       "      <td>0.991930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.068851</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.072809</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075512</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075477</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cdfea44434423299c9deed7db4b7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTNEG0\n",
      "   03b942e..f913314  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTNEG0\n",
      "   f913314..f93ff01  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.57 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.57 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a752fa1-1bf0-4ad6-9d83-a016eede1d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3963  940]\n",
      " [  46    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      4903\n",
      "           1       0.01      0.15      0.02        54\n",
      "\n",
      "    accuracy                           0.80      4957\n",
      "   macro avg       0.50      0.48      0.45      4957\n",
      "weighted avg       0.98      0.80      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8b9f9e-b564-4d9b-b7fb-0c154ee4ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTicSENTNEG0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767f6f81fe1e46d5bfb8cdc7d04d4c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 7.90k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11514a625cfe473bbb1370781699f9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 25:30, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059820</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031852</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>0.986550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.038234</td>\n",
       "      <td>0.983860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048413</td>\n",
       "      <td>0.980498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.044417</td>\n",
       "      <td>0.985878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.039808</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.039910</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.040095</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.042651</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>0.993275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.044449</td>\n",
       "      <td>0.989240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.044171</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eb44160af54d94a4bf22383d12c54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTNEG0\n",
      "   027181b..37478f1  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTNEG0\n",
      "   37478f1..cbc19de  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.21 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.21 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90d6098e-82b3-471b-8cb2-cfd6ac416ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3cc315f8b14b81b89991876dbf6aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99bef41c6904182836c3c3c2c74696a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac07b3c1aaf04619b47af1ae82f908f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8e567cae634f189d5aadd15ac1b6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c5ef1836c54e268d8f06ba7256364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3e766e609a47d5b8e501e630930ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4871   32]\n",
      " [  11   43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      4903\n",
      "           1       0.57      0.80      0.67        54\n",
      "\n",
      "    accuracy                           0.99      4957\n",
      "   macro avg       0.79      0.89      0.83      4957\n",
      "weighted avg       0.99      0.99      0.99      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ef7d75-69bc-4e6d-a451-24947bc2cdf1",
   "metadata": {},
   "source": [
    "### Refined Fine-Tuning: Optimizing for F1 Score\r\n",
    "\r\n",
    "In our ongoing pursuit for improved model performance, we'll adapt our fine-tuning strategy. This time, we aim to optimize for the F1 score during the evaluation process. The F1 score is a balanced measure of both precision and recall, making it a valuable metric for model evaluation, especially in imbalanced datasets. By placing a stronger emphasis on this metric, we aspire to enhance the overall effectiveness of our model. Let's proceed to see if this approach yields better results.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feed41c8-2480-47ac-9d7f-a9d66ab43d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTicSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTicSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 26:11, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024439</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.035923</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.029715</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017461</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023793</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024401</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021950</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.021709</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.024938</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.022811</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f16584353a4dfcaee5188f67c3b340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   19b03c2..254c9df  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTPOS0\n",
      "   254c9df..8df5cab  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.11 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.11 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"POS\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cbb657f-36d8-4f0b-a0a2-2c92dfa03bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46509bb5cf29462fa3c6c6170d08ab75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b716653378499e89c33ad6747b3fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cf0b86ad9c4098b35b8784a230fe87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8c9ea31fe646cc8ca6aa1d7e669739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9c3a62df0241248b347a95482c824b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59731b772fca44b7a901d797e3eb579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4912    8]\n",
      " [  15   22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4920\n",
      "           1       0.73      0.59      0.66        37\n",
      "\n",
      "    accuracy                           1.00      4957\n",
      "   macro avg       0.87      0.80      0.83      4957\n",
      "weighted avg       0.99      1.00      1.00      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf289631-0b42-4fb0-9d1d-5f111bbcc7d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTicSENTNEG0 is already a clone of https://huggingface.co/Tanor/BERTicSENTNEG0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 26:35, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.037483</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030406</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.046774</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.051798</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.050233</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.063212</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.051690</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.055864</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.055952</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.055315</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.053921</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.055369</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.055560</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ae772c7b14109945779171d478686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTNEG0\n",
      "   b7ee491..9290755  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTNEG0\n",
      "   9290755..8774c4b  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.22 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.22 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"NEG\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc145527-25c0-4935-8379-e17151dfe81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba30cfd18b447ec8cdf66360fb58410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b5dd3479df4079873860769308c514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90672eaae503470e826396b688d121ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74218f1c4fa945e58cc96c3f359ab66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8dd852ac1f477caa3b30a2f63498da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa3d1e43ab04e4396968079bd54ba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4879   24]\n",
      " [  13   41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4903\n",
      "           1       0.63      0.76      0.69        54\n",
      "\n",
      "    accuracy                           0.99      4957\n",
      "   macro avg       0.81      0.88      0.84      4957\n",
      "weighted avg       0.99      0.99      0.99      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59777033-32c4-49db-91de-71be72355654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTovoSENTPOS0 is already a clone of https://huggingface.co/Tanor/BERTovoSENTPOS0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 29:39, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017485</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.020884</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.031966</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029005</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030144</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   cf19cd7..12fba94  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   12fba94..c1e5219  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.88 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.88 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"POS\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffba4a63-777d-496a-b607-1dc1b0058903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3946  974]\n",
      " [  31    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      4920\n",
      "           1       0.01      0.16      0.01        37\n",
      "\n",
      "    accuracy                           0.80      4957\n",
      "   macro avg       0.50      0.48      0.45      4957\n",
      "weighted avg       0.98      0.80      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51366b0c-fcde-48da-a07b-3dfe87c15186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTovoSENTNEG0 is already a clone of https://huggingface.co/Tanor/BERTovoSENTNEG0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 29:00, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036160</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030631</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036069</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.041809</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.048620</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054190</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.061454</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.063018</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.064784</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.068851</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.071473</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.072809</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075512</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.075477</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02ff70ada3148f98767a30a7ae249fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at 06f34f97472edefcfda31cb5543bc5339ccf452d but expected f04cade6e433b4e4d4365d6f5062b0388e9e8e99        \n",
      "To https://huggingface.co/Tanor/BERTovoSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/BERTovoSENTNEG0'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at 06f34f97472edefcfda31cb5543bc5339ccf452d but expected f04cade6e433b4e4d4365d6f5062b0388e9e8e99        \nTo https://huggingface.co/Tanor/BERTovoSENTNEG0\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Tanor/BERTovoSENTNEG0'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1099\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[1;32m-> 1099\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainBERTovo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNEG\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\trainBERTovo.py:124\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(i, polarity, eval, epochs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Train model and push to hub\u001b[39;00m\n\u001b[0;32m    123\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 124\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Show GPU memory usage before and after deleting the model and datasets\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMax memory allocated by tensors- before:\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\trainer.py:3738\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mkill()\n\u001b[0;32m   3736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3738\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   3740\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3741\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[0;32m   3742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1307\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m-> 1307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1102\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[1;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at 06f34f97472edefcfda31cb5543bc5339ccf452d but expected f04cade6e433b4e4d4365d6f5062b0388e9e8e99        \nTo https://huggingface.co/Tanor/BERTovoSENTNEG0\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Tanor/BERTovoSENTNEG0'\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"NEG\", eval=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac70724-38c2-4cdc-b02d-740afc14009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3963  940]\n",
      " [  46    8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      4903\n",
      "           1       0.01      0.15      0.02        54\n",
      "\n",
      "    accuracy                           0.80      4957\n",
      "   macro avg       0.50      0.48      0.45      4957\n",
      "weighted avg       0.98      0.80      0.88      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1308e0ba-40f7-44b4-b4a7-612be0a1f701",
   "metadata": {},
   "source": [
    "### Advancing to Iteration 2: Continuation with F1 Score Optimization\r\n",
    "\r\n",
    "Following the slight improvements achieved in our previous iteration through F1 score optimization, we will continue to apply this strategy in our model's training processWe aslo double number epochs since previusn itteration had been trained twice:r.\r\n",
    "y.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43998619-c748-41a0-9fb0-234c6c2211ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c26089d81de4cec8f293cfd0b1b132a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781b651b3d32449896f01b27712cad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86dff78b444bb9af5f233cbd6168c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20e9a9bbd6c4e97897f06788107d75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38e3488f9364259be991d00726f16b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/922 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8a9315751742ec8970af7fac164459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTicSENTPOS2 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d4bff2efe64965b721b9853642652e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 7.37k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f14456a3982482284bd5fb2fff6035d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1696' max='1696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1696/1696 54:07, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069619</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.041346</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.047974</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.036129</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.040689</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.039289</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.042570</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045153</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.055570</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.050119</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.056938</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.055225</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.049627</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.053161</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.058343</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.055530</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.057472</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.057498</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.057873</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.060183</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.061064</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.063182</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.063392</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31448b1c624466984e9e3f43447f9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at dd178b976cc5ade95ac4156636e4bc5175ae543d but expected 159865507dea40010a0607174e1a88d440d8e163        \n",
      "To https://huggingface.co/Tanor/BERTicSENTPOS2\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/BERTicSENTPOS2'\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "remote: error: cannot lock ref 'refs/heads/main': is at dd178b976cc5ade95ac4156636e4bc5175ae543d but expected 159865507dea40010a0607174e1a88d440d8e163        \nTo https://huggingface.co/Tanor/BERTicSENTPOS2\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Tanor/BERTicSENTPOS2'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1099\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m return_code:\n\u001b[1;32m-> 1099\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['git', 'push', '--set-upstream', 'origin', 'main']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainBERTic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\trainBERTic.py:129\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(i, polarity, eval, epochs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Train model and push to hub\u001b[39;00m\n\u001b[0;32m    128\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 129\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Show GPU memory usage before and after deleting the model and datasets\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMax memory allocated by tensors- before:\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\trainer.py:3738\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3735\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress\u001b[38;5;241m.\u001b[39m_process\u001b[38;5;241m.\u001b[39mkill()\n\u001b[0;32m   3736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3738\u001b[0m git_head_commit_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   3740\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3741\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[0;32m   3742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1307\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_add(auto_lfs_track\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m-> 1307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_push\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morigin \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_branch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\repository.py:1102\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError(return_code, process\u001b[38;5;241m.\u001b[39margs, output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blocking:\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstatus_method\u001b[39m():\n",
      "\u001b[1;31mOSError\u001b[0m: remote: error: cannot lock ref 'refs/heads/main': is at dd178b976cc5ade95ac4156636e4bc5175ae543d but expected 159865507dea40010a0607174e1a88d440d8e163        \nTo https://huggingface.co/Tanor/BERTicSENTPOS2\n ! [remote rejected] main -> main (failed to update ref)\nerror: failed to push some refs to 'https://huggingface.co/Tanor/BERTicSENTPOS2'\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(2, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cc8971-4810-4fc3-a78b-ae026892e1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab81e10157747c4b4a7bc56fc310086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1c6ad0ab6a43a2b00be37d250c4104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c1fb391eca41bb985bc9aecaae5947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca072093afd495fa0b6918ceec927ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2954b8fc0a940dbb994ed1b1336759b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6097a2f011944e348f85ecb830e1f2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4928   14]\n",
      " [  33   33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4942\n",
      "           1       0.70      0.50      0.58        66\n",
      "\n",
      "    accuracy                           0.99      5008\n",
      "   macro avg       0.85      0.75      0.79      5008\n",
      "weighted avg       0.99      0.99      0.99      5008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(2, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d200a6-440b-4928-91e4-1b12f6487798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d8741556454eb49f645422c061c238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a409b9a5c248229509c689d648e649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9b7d1d1c334f40b4daccb53e3f0666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb476cf46eb482d8f8c3b0c9e5f66ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f898510805574111bad75706141160ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/922 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5a289979134511a8e370a4f31d874a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTicSENTNEG2 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2161c976e3fa44689b5a47ba507bd934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 15.4k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54684c733f849a692a1f6d7529d8ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1696' max='1696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1696/1696 52:54, Epoch 32/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077397</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.040422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.033915</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.039870</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>0.634146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.046730</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.051240</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.062709</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.054687</td>\n",
       "      <td>0.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.061026</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.064294</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.062323</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.065197</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.059452</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.064431</td>\n",
       "      <td>0.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.068041</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.071366</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.068853</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.075560</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.076096</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.075485</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.071257</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.073226</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.074641</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.612245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4577d2e90b4f4ee5aac6bd82ac5329f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTicSENTNEG2\n",
      "   cc4b5e9..0375828  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTicSENTNEG2\n",
      "   0375828..f5a83f6  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.22 GB\n",
      "Max memory allocated by tensors- after:\n",
      "    2.22 GB\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.train_model(2, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6670ca2b-e26c-42ba-88ce-b7916e3ac6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7fc04b12824708ae1e0f1f0922f099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/972 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a8a94c1d1d43d89a91e1f763f6a7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70dd797c7156484c8b0fc6b28f09fc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e519f6c3794a48a4bced60dd592db030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ff7f147fb54dd686f8cf0bd778c20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed79c721aea418fab7e1ee9e10c2bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4905   27]\n",
      " [  25   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4932\n",
      "           1       0.65      0.67      0.66        76\n",
      "\n",
      "    accuracy                           0.99      5008\n",
      "   macro avg       0.82      0.83      0.83      5008\n",
      "weighted avg       0.99      0.99      0.99      5008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTic.test_model(2, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fddb7b2-b082-430c-b730-c54b719ecc88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1503 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13520 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\BERTovoSENTPOS2 is already a clone of https://huggingface.co/Tanor/BERTovoSENTPOS2. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='1696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 142/1696 04:46 < 53:05, 0.49 it/s, Epoch 2.66/32]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.069187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.046341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainBERTovo.train_model(2, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b875fbb-7a3b-4574-b8d3-a8f7fdcb736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(2, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25537dbe-ddcb-4d83-a71a-2f9ab9d80d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTovo.train_model(2, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcfd82e-8f61-416d-a742-a37723c78d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(2, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e782287-053e-41f6-b23c-c16ae91aa7ac",
   "metadata": {},
   "source": [
    "MOving to itteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802c4dc-ceca-4e5c-9449-fe7f3c5ddbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTic.train_model(4, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1ba70-a5eb-473b-bf9f-805b7abdaa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b24f1f-4a85-404c-8100-25c57241396e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTic.train_model(4, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14351b26-17a1-452e-9f26-a227badb8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(4, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e3a4c-f43f-4e0b-b4ff-b6eae612b926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTovo.train_model(4, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b15db-0af5-41cf-abe5-9f5f23886305",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(4, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d618f-0511-4b50-9093-a011eb339a23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTovo.train_model(4, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709377b2-b290-4178-9a3e-b544f5adeaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(4, \"NEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519f333-3fb7-4dfd-8674-3595bfd236ab",
   "metadata": {},
   "source": [
    "Iterration 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86da46f-2550-48fa-a00b-fe7afc8f5f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTic.train_model(6, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bebde0-10a3-4a57-8577-bb0fec616120",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(6, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ebad0b-9ba7-47b7-a182-0c4d612ac890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTic.train_model(6, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd478f29-442d-468f-9c30-433947ddd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(6, \"NEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87336ce9-510e-444d-814c-87b30742b3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTovo.train_model(6, \"POS\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd82c49-f18c-4ec7-893e-6e221ea43fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(6, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266345c-9a23-472d-94c2-92491a3a1db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainBERTovo.train_model(6, \"NEG\", eval=\"f1\", epochs = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa7a43-7c56-415e-a0c2-78bb9ac7d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTovo.test_model(6, \"NEG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
