{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0ef077-027d-454d-b811-6caa42e1f0b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\SRGPTSENTNEG0 is already a clone of https://huggingface.co/Tanor/SRGPTSENTNEG0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2973' max='2973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2973/2973 55:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.094851</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd65b6f50c448fc8e1ad4123c534289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at 06bf695a7eec207d7e90f3ad84c2cdd666b46180 but expected f7e36a63f16837acfce931f5df4bebf6ffd63a40        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n",
      "Error pushing update to the model card. Please read logs and retry.\n",
      "$remote: error: cannot lock ref 'refs/heads/main': is at 06bf695a7eec207d7e90f3ad84c2cdd666b46180 but expected f7e36a63f16837acfce931f5df4bebf6ffd63a40        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "6.42 GB\n",
      "[[4895    8]\n",
      " [  38   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4903\n",
      "           1       0.67      0.30      0.41        54\n",
      "\n",
      "    accuracy                           0.99      4957\n",
      "   macro avg       0.83      0.65      0.70      4957\n",
      "weighted avg       0.99      0.99      0.99      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run trainSRGPT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05975c89-0131-4d57-9b46-be9bfad202fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\SRGPTSENTNEG0 is already a clone of https://huggingface.co/Tanor/SRGPTSENTNEG0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2973' max='2973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2973/2973 54:24, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.100305</td>\n",
       "      <td>0.989913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33385f85219a4d1998fa1f32b78f005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/2.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: error: cannot lock ref 'refs/heads/main': is at 3afb6a766f061012d29bc8d8c60fd33288c0a7b2 but expected 06bf695a7eec207d7e90f3ad84c2cdd666b46180        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n",
      "Error pushing update to the model card. Please read logs and retry.\n",
      "$remote: error: cannot lock ref 'refs/heads/main': is at 3afb6a766f061012d29bc8d8c60fd33288c0a7b2 but expected 06bf695a7eec207d7e90f3ad84c2cdd666b46180        \n",
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      " ! [remote rejected] main -> main (failed to update ref)\n",
      "error: failed to push some refs to 'https://huggingface.co/Tanor/SRGPTSENTNEG0'\n",
      "\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors:\n",
      "6.42 GB\n",
      "[[4894    9]\n",
      " [  38   16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      4903\n",
      "           1       0.64      0.30      0.41        54\n",
      "\n",
      "    accuracy                           0.99      4957\n",
      "   macro avg       0.82      0.65      0.70      4957\n",
      "weighted avg       0.99      0.99      0.99      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run trainSRGPT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b036b6-09db-4814-b356-35a25088b00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662abbeb439a4609aba53d035b5d1b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8017a6c9da3449b083c34036598d0fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/832k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee07b7bf17e4cb9b3093ea7ea842bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/498k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692fc207fb384dcb8d42e8fd835bc7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d165fd2234074afcb349478eba994895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8d4b3e4f2a41d7a5159aa57564fa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5686a52cb5be45b0bc6ba9a65fcf6506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3aba3a27c14a24a19a18e12e93b6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sasa5\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\SRGPTSENTNEG0 is already a clone of https://huggingface.co/Tanor/SRGPTSENTNEG0. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2973' max='2973' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2973/2973 55:12, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.220697</td>\n",
       "      <td>0.988904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Trainer.create_model_card() got an unexpected keyword argument 'force'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\trainSRGPT.py:153\u001b[0m\n\u001b[0;32m    126\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m    127\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mouputdir,\n\u001b[0;32m    128\u001b[0m     overwrite_output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m     push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m )\n\u001b[0;32m    143\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    144\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    145\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    154\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMax memory allocated by tensors:\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\transformers\\trainer.py:3743\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3741\u001b[0m \u001b[38;5;66;03m# push separately the model card to be independant from the rest of the model\u001b[39;00m\n\u001b[0;32m   3742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m-> 3743\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3744\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   3745\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mpush_to_hub(\n\u001b[0;32m   3746\u001b[0m             commit_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate model card README.md\u001b[39m\u001b[38;5;124m\"\u001b[39m, blocking\u001b[38;5;241m=\u001b[39mblocking, auto_lfs_prune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3747\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: Trainer.create_model_card() got an unexpected keyword argument 'force'"
     ]
    }
   ],
   "source": [
    "%run trainSRGPT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec55c8c-5120-40c3-b8fe-288a0b09bf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/SRGPTSENTNEG0\n",
      "   7beaf3e..0f4ef1b  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Tanor/SRGPTSENTNEG0/commit/0f4ef1b1da73181ce65d296bfe733470de78410a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22035c87-07e7-4cc2-8cb3-a179d773ba2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
