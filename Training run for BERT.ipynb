{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a24020-7015-4083-bdbd-1347029fa855",
   "metadata": {},
   "source": [
    "# Fine-Tuning and Evaluating Sequence Classification Models\r\n",
    "\r\n",
    "In this notebook, we'll take the next steps in our project: we'll fine-tune our prepared BERT models on our training set and evaluate their performance. \r\n",
    "\r\n",
    "This process involves running Python scripts that execute the training process and test the resulting models on our test set. The metrics of our models' performance are crucial in understanding how well our fine-tuning process has worked. We will look at these metrics in two ways: \r\n",
    "\r\n",
    "1. **In-notebook review:** We'll print the confusion matrix and classification reports within this notebook for an immediate review of our models' performance.\r\n",
    "\r\n",
    "2. **Saving reports:** To ensure we have a permanent record of our results, we'll also save these performance metrics in a separate 'reports' folder. This allows us to track our progress over time and make comparisons between different models and iterations of fine-tuning.\r\n",
    "\r\n",
    "Remember, the fine-tuning and evaluation process can be iterative. Based on the results we see in our reports, we may want to adjust our approach and fine-tune our models differently. \r\n",
    "\r\n",
    "In this notebook, we'll cover the following steps:\r\n",
    "\r\n",
    "1. Running the training scripts: We'll call our Python scripts that handle the fine-tuning of our models on the training set.\r\n",
    "2. Running the testing scripts: We'll test the performance of our newly fine-tuned models on our test set.\r\n",
    "3. Reviewing the results: We'll print and save our confusion matrices and classification reports.\r\n",
    "\r\n",
    "Let's get started!\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5c4a21-c270-43f4-8cc1-ec50fec917c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainBERTovo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8dae72-065b-40df-972f-b4c8267c9146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTovoSENTPOS0 into local empty directory.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 28:04, Epoch 15/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.032228</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025992</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.019655</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.990585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.022347</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025427</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.024218</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.029928</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.993948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.029364</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.029690</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96f12e6bec349e6ae4788e0bd64b83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 1.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   84a7fd9..c6b7586  main -> main\n",
      "\n",
      "To https://huggingface.co/Tanor/BERTovoSENTPOS0\n",
      "   c6b7586..697e4b6  main -> main\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max memory allocated by tensors- before:\n",
      "    2.39 GB\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'dataset_train' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainBERTovo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\SerbianSentiWordNET\\trainBERTovo.py:130\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(i, polarity)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tokenised_train\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m dataset_train\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mdataset_train\u001b[49m\n\u001b[0;32m    131\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mMax memory allocated by tensors- after:\u001b[39m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'dataset_train' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "trainBERTovo.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4755b897-48d8-443c-b25b-c0b11e939862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3218 1702]\n",
      " [  25   12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.65      0.79      4920\n",
      "           1       0.01      0.32      0.01        37\n",
      "\n",
      "    accuracy                           0.65      4957\n",
      "   macro avg       0.50      0.49      0.40      4957\n",
      "weighted avg       0.98      0.65      0.78      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainBERTovo.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f778f6-3e9b-4e86-88f5-df36f79c90b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import trainBERTic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73125c37-14f2-48eb-95e2-fc3fd9ec940e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e43582587c4bb1bde7a12498fec852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sasa5\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de87017ad174851aa72ae8aa5404c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575c6f2db18b495fb631005c0c138f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/734k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828eec5fa5c84d99b25ea9a8c062eeac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bcde7880714726a3aa9ecfa44a88c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/922 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f724a06de2b04d2588d1e113454ea0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/Tanor/BERTicSENTPOS0 into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe994965c6e248e3a93f26930fb2e71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Download file pytorch_model.bin:   0%|          | 17.4k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc1a2ef70994f1b9fa4bc907dede757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Clean file pytorch_model.bin:   0%|          | 1.00k/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='814' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [814/832 24:42 < 00:32, 0.55 it/s, Epoch 15.49/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045899</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>0.993275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.991258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.995965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.012243</td>\n",
       "      <td>0.997310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.994620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013211</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013910</td>\n",
       "      <td>0.995293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.996638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainBERTic.train_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0705446-4984-4b9d-9de6-b125cc2912fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBERTic.test_model(0, \"POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382eb9a-2eb5-4b73-a693-9d13166009d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
